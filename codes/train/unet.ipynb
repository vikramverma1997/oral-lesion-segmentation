{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sm-unet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "61mCuCmh9LYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git config --global --unset http.proxy \n",
        "!git config --global --unset https.proxy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ6zVXhAO7UP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install q tensorflow==2.1\n",
        "!pip install q keras==2.3.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4U0EbpQ9Wyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install -U albumentations\n",
        "!pip install -U segmentation-models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjzOIbnYJQc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "print(keras.__version__)\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utKfru__TimC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import albumentations as A\n",
        "import segmentation_models as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HomZgJPdBC6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKty-6NYBKNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = '/content/oral-cancer-data/'\n",
        "\n",
        "# load repo with data if it is not exists\n",
        "if not os.path.exists(DATA_DIR): print('load data!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB5bI2r9Ymad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of images\")\n",
        "!ls ./oral-cancer-data/train/images/ | wc -l\n",
        "print(\"Number of masks\")\n",
        "!ls ./oral-cancer-data/train/labels/ | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoh7RQ2NBb9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_dir = os.path.join(DATA_DIR, 'train', 'images')\n",
        "y_train_dir = os.path.join(DATA_DIR, 'train', 'labels')\n",
        "\n",
        "x_test_dir = os.path.join(DATA_DIR, 'test', 'images')\n",
        "y_test_dir = os.path.join(DATA_DIR, 'test', 'labels')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIFpOC5rBwSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper function for data visualization\n",
        "def visualize(**images):\n",
        "    \"\"\"PLot images in one row.\"\"\"\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "    \n",
        "# helper function for data visualization    \n",
        "def denormalize(x):\n",
        "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
        "    x_max = np.percentile(x, 98)\n",
        "    x_min = np.percentile(x, 2)    \n",
        "    x = (x - x_min) / (x_max - x_min)\n",
        "    x = x.clip(0, 1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhhzb_zYCJRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classes for data loading and preprocessing\n",
        "class Dataset:\n",
        "    \"\"\"Read images, apply augmentation and preprocessing transformations.\n",
        "    \n",
        "    Args:\n",
        "        images_dir (str): path to images folder\n",
        "        masks_dir (str): path to segmentation masks folder\n",
        "        class_values (list): values of classes to extract from segmentation mask\n",
        "        augmentation (albumentations.Compose): data transfromation pipeline \n",
        "            (e.g. flip, scale, etc.)\n",
        "        preprocessing (albumentations.Compose): data preprocessing \n",
        "            (e.g. noralization, shape manipulation, etc.)\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    CLASSES = ['lesion']\n",
        "    \n",
        "    def __init__(\n",
        "            self, \n",
        "            images_dir, \n",
        "            masks_dir, \n",
        "            classes=None, \n",
        "            augmentation=None, \n",
        "            preprocessing=None,\n",
        "    ):\n",
        "        self.ids = os.listdir(images_dir)\n",
        "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
        "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
        "        \n",
        "        # convert str names to class values on masks\n",
        "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
        "        \n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # read data\n",
        "        image = cv2.imread(self.images_fps[i])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (256, 256))\n",
        "\n",
        "        mask = cv2.imread(self.masks_fps[i], 0)\n",
        "        mask = cv2.resize(mask, (256, 256))\n",
        "        \n",
        "        # extract certain classes from mask (e.g. cars)\n",
        "        masks = [(mask == v) for v in self.class_values]\n",
        "        mask = np.stack(masks, axis=-1).astype('float')\n",
        "        mask = np.where(mask>0, 0, 1)\n",
        "        \n",
        "        # add background if mask is not binary\n",
        "        if mask.shape[-1] != 1:\n",
        "            background = 1 - mask.sum(axis=-1, keepdims=True)\n",
        "            mask = np.concatenate((mask, background), axis=-1)\n",
        "        \n",
        "        # apply augmentations\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "        \n",
        "        # apply preprocessing\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "            \n",
        "        return image, mask\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "    \n",
        "    \n",
        "class Dataloder(keras.utils.Sequence):\n",
        "    \"\"\"Load data from dataset and form batches\n",
        "    \n",
        "    Args:\n",
        "        dataset: instance of Dataset class for image loading and preprocessing.\n",
        "        batch_size: Integet number of images in batch.\n",
        "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(dataset))\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # collect batch data\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "        \n",
        "        # transpose list of lists\n",
        "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
        "        \n",
        "        return batch\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
        "        return len(self.indexes) // self.batch_size\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
        "        if self.shuffle:\n",
        "            self.indexes = np.random.permutation(self.indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jehBOduC0He",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets look at data we have\n",
        "dataset = Dataset(x_train_dir, y_train_dir, classes=['lesion'])\n",
        "\n",
        "image, mask = dataset[7] # get some sample\n",
        "print(\"image shape: {} and mask shape: {}\".format(image.shape,mask.shape))\n",
        "visualize(\n",
        "    image=image, \n",
        "    lesion_mask=mask[..., 0].squeeze()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilgnx2h5Dj7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def round_clip_0_1(x, **kwargs):\n",
        "#     return x.round().clip(0, 1)\n",
        "\n",
        "# # define heavy augmentations\n",
        "# def get_training_augmentation():\n",
        "#     train_transform = [\n",
        "\n",
        "#         A.HorizontalFlip(p=0.5),\n",
        "\n",
        "#         A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.25, rotate_limit=0, p=1, border_mode=0),\n",
        "\n",
        "#         A.PadIfNeeded(min_height=256, min_width=256, always_apply=True, border_mode=0),\n",
        "#         # A.RandomCrop(height=256, width=256, always_apply=True),\n",
        "\n",
        "#         # A.IAAAdditiveGaussianNoise(p=0.2),\n",
        "#         # A.IAAPerspective(p=0.5),\n",
        "\n",
        "#         # A.OneOf(\n",
        "#         #     [\n",
        "#         #         A.CLAHE(p=1),\n",
        "#         #         A.RandomBrightness(p=1),\n",
        "#         #         A.RandomGamma(p=1),\n",
        "#         #     ],\n",
        "#         #     p=0.9,\n",
        "#         # ),\n",
        "\n",
        "#         # A.OneOf(\n",
        "#         #     [\n",
        "#         #         A.IAASharpen(p=1),\n",
        "#         #         A.Blur(blur_limit=3, p=1),\n",
        "#         #         A.MotionBlur(blur_limit=3, p=1),\n",
        "#         #     ],\n",
        "#         #     p=0.9,\n",
        "#         # ),\n",
        "\n",
        "#         # A.OneOf(\n",
        "#         #     [\n",
        "#         #         A.RandomContrast(p=1),\n",
        "#         #         A.HueSaturationValue(p=1),\n",
        "#         #     ],\n",
        "#         #     p=0.9,\n",
        "#         # ),\n",
        "#         A.Lambda(mask=round_clip_0_1)\n",
        "#     ]\n",
        "#     return A.Compose(train_transform)\n",
        "\n",
        "\n",
        "# def get_validation_augmentation():\n",
        "#     \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
        "#     test_transform = [\n",
        "#         A.PadIfNeeded(256, 256)\n",
        "#     ]\n",
        "#     return A.Compose(test_transform)\n",
        "\n",
        "def get_preprocessing(preprocessing_fn):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "    \n",
        "    Args:\n",
        "        preprocessing_fn (callbale): data normalization function \n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    _transform = [\n",
        "        A.Lambda(image=preprocessing_fn),\n",
        "    ]\n",
        "    return A.Compose(_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8CZHv7KDmva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Lets look at augmented data we have\n",
        "# dataset = Dataset(x_train_dir, y_train_dir, classes=['lesion'), augmentation=get_training_augmentation())\n",
        "\n",
        "# image, mask = dataset[7] # get some sample\n",
        "# print(\"image shape: {} and mask shape: {}\".format(image.shape,mask.shape))\n",
        "# visualize(\n",
        "#     image=image, \n",
        "#     lesion_mask=mask[..., 0].squeeze()\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaxLDi5WFWYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BACKBONE = 'efficientnetb3'\n",
        "BATCH_SIZE = 8\n",
        "CLASSES = ['lesion']\n",
        "LR = 0.0001\n",
        "EPOCHS = 400\n",
        "\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsnKzwwSFfJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define network parameters\n",
        "n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES) + 1)  # case for binary and multiclass segmentation\n",
        "activation = 'sigmoid' if n_classes == 1 else 'softmax'\n",
        "\n",
        "#create model\n",
        "model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H04QIuCAFjwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim = keras.optimizers.Adam(LR)\n",
        "\n",
        "total_loss = sm.losses.binary_focal_dice_loss + (1 * sm.losses.binary_crossentropy)\n",
        "\n",
        "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
        "\n",
        "# compile keras model with defined optimozer, loss and metrics\n",
        "model.compile(optim, total_loss, metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ifz3w-2FpUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset for train images\n",
        "train_dataset = Dataset(\n",
        "    x_train_dir, \n",
        "    y_train_dir, \n",
        "    classes=CLASSES, \n",
        "    # augmentation=get_training_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocess_input)\n",
        ")\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "print(train_dataloader[0][0].shape, train_dataloader[0][1].shape)\n",
        "# check shapes for errors\n",
        "assert train_dataloader[0][0].shape == (BATCH_SIZE, 256, 256, 3)\n",
        "assert train_dataloader[0][1].shape == (BATCH_SIZE, 256, 256, n_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cKKCS6CLNyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def schedule(EPOCHS, LR):\n",
        "#   if EPOCHS < 150:\n",
        "#     return LR;\n",
        "#   elif LR < 1e-6:\n",
        "#     return 1e-6\n",
        "#   else:\n",
        "#     return LR * 0.3\n",
        "\n",
        "# # define callbacks for learning rate scheduling\n",
        "# callbacks = [\n",
        "#     keras.callbacks.LearningRateScheduler(schedule, verbose=1)\n",
        "# ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa3pzk3OF6V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train model\n",
        "history = model.fit_generator(\n",
        "    train_dataloader, \n",
        "    steps_per_epoch=len(train_dataloader), \n",
        "    epochs=EPOCHS\n",
        "    # callbacks=callbacks,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmszRR3vTMKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"unet_{}_weights.h5\".format(BACKBONE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1_jtORPUNr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weLtBLWmIRLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training iou_score values\n",
        "plt.figure(figsize=(30, 5))\n",
        "plt.subplot(121)\n",
        "plt.plot(history.history['iou_score'])\n",
        "plt.plot(history.history['f1-score'])\n",
        "plt.title('Model scores')\n",
        "plt.ylabel('Scores')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['IOU score', 'F1 score'], loc='upper left')\n",
        "\n",
        "# Plot training loss values\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0oZdT3UIaRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = Dataset(\n",
        "    x_test_dir, \n",
        "    y_test_dir, \n",
        "    classes=CLASSES, \n",
        "    # augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocess_input)\n",
        ")\n",
        "\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08kb77pYRFmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load best weights\n",
        "model.load_weights('/content/unet_efficientnetb3_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciUVKGb2nzJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores_100 = scores\n",
        "print(scores_100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOmbsNL_RVIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = model.evaluate_generator(test_dataloader)\n",
        "\n",
        "print(\"Loss: {:.5}\".format(scores[0]))\n",
        "for metric, value in zip(metrics, scores[1:]):\n",
        "    print(\"mean {}: {:.5}\".format(metric.__name__, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGOg3wyXSp1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 5\n",
        "ids = np.random.choice(np.arange(len(test_dataset)), size=n, replace=False)\n",
        "\n",
        "for i in ids:\n",
        "    \n",
        "    image, gt_mask = test_dataset[i]\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    pr_mask = model.predict(image).round()\n",
        "    \n",
        "    visualize(\n",
        "        image=denormalize(image.squeeze()),\n",
        "        gt_mask=gt_mask[..., 0].squeeze(),\n",
        "        pr_mask=pr_mask[..., 0].squeeze(),\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSBIzCE5jLNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 22 # on train dataset\n",
        "ids = np.random.choice(np.arange(len(train_dataset)), size=n, replace=False)\n",
        "\n",
        "for i in ids:\n",
        "    \n",
        "    image, gt_mask = train_dataset[i]\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    pr_mask = model.predict(image).round()\n",
        "    \n",
        "    visualize(\n",
        "        image=denormalize(image.squeeze()),\n",
        "        gt_mask=gt_mask[..., 0].squeeze(),\n",
        "        pr_mask=pr_mask[..., 0].squeeze(),\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcliOi8Krj9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}