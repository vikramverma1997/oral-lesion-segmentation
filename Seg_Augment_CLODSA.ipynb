{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GxQekSqTht6I"
   },
   "source": [
    "# Augmenting a dataset for semantic segmentation\n",
    "\n",
    "In this notebook, we illustrate how CLODSA can be employed to augment a dataset of images devoted to semantic segmentation. In particular, we use the dataset provided for the [2018 Data Science Bowl](https://www.kaggle.com/c/data-science-bowl-2018), that is divoted to find the nucle in divergent images to advance medical discovery - from now on we will call this dataset, the Nuclei dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YC_9o6-Jht6M"
   },
   "source": [
    "The Nuclei training dataset consists of 670 nucle images and their corresponding lbels. For illustration purposes, we take a subset of the Nucle dataset containing 100 images. Such a subset can be downloaded by executing the following command. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kAy0Hvnbht6i"
   },
   "source": [
    "We can check the amount of images in each one of the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clodsa in /home/ritesh/vm1/lib/python3.6/site-packages (1.2.39)\n",
      "Requirement already satisfied: numpy in /home/ritesh/vm1/lib/python3.6/site-packages (from clodsa) (1.18.5)\n",
      "Requirement already satisfied: scipy in /home/ritesh/vm1/lib/python3.6/site-packages (from clodsa) (1.4.1)\n",
      "Requirement already satisfied: Keras in /home/ritesh/vm1/lib/python3.6/site-packages (from clodsa) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in /home/ritesh/vm1/lib/python3.6/site-packages (from clodsa) (0.22.1)\n",
      "Requirement already satisfied: mahotas in /home/ritesh/vm1/lib/python3.6/site-packages (from clodsa) (1.4.9)\n",
      "Requirement already satisfied: commentjson in /home/ritesh/vm1/lib/python3.6/site-packages (from clodsa) (0.8.3)\n",
      "Requirement already satisfied: h5py in /home/ritesh/vm1/lib/python3.6/site-packages (from clodsa) (2.10.0)\n",
      "Requirement already satisfied: progressbar2 in /home/ritesh/vm1/lib/python3.6/site-packages (from clodsa) (3.51.3)\n",
      "Requirement already satisfied: imutils in /home/ritesh/vm1/lib/python3.6/site-packages (from clodsa) (0.5.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ritesh/vm1/lib/python3.6/site-packages (from Keras->clodsa) (1.1.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ritesh/vm1/lib/python3.6/site-packages (from Keras->clodsa) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in /home/ritesh/vm1/lib/python3.6/site-packages (from Keras->clodsa) (5.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ritesh/vm1/lib/python3.6/site-packages (from Keras->clodsa) (1.0.8)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ritesh/vm1/lib/python3.6/site-packages (from scikit-learn->clodsa) (0.15.1)\n",
      "Requirement already satisfied: lark-parser<0.8.0,>=0.7.1 in /home/ritesh/vm1/lib/python3.6/site-packages (from commentjson->clodsa) (0.7.8)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /home/ritesh/vm1/lib/python3.6/site-packages (from progressbar2->clodsa) (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install clodsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "XEJ0pRfRht6k",
    "outputId": "9cc7906d-f241-403d-b41e-7b8b4ff9112c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images\n",
      "9092\n",
      "Number of masks\n",
      "9092\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images\")\n",
    "!ls /home/ritesh/hdd1/vikram/ER_PR/extracted_patches/train/images/ | wc -l\n",
    "print(\"Number of masks\")\n",
    "!ls /home/ritesh/hdd1/vikram/ER_PR/extracted_patches/train/labels/ | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LaBilQHUht6u"
   },
   "source": [
    "## Augmentation techniques\n",
    "\n",
    "For this example, we consider the augmentation techniques applied in the work [\"U-Net: Convolutional Networks for Biomedical Image Segmentation\"](https://arxiv.org/abs/1505.04597), where they present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. Using such an approach, they won the [ISBI challenge for segmentation of neuronal structures in electron microscopic stacks](http://brainiac2.mit.edu/isbi_challenge/home). \n",
    "\n",
    "The augmentation techniques applied in that work are:\n",
    "- Shifting.\n",
    "- Rotation.\n",
    "- Elastic deformations.\n",
    "\n",
    "In addition, we also apply gamma correction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I1q3x_OFht66"
   },
   "source": [
    "## Loading the necessary libraries\n",
    "\n",
    "The first step in the pipeline consists in loading the necessary libraries to apply the data augmentation techniques in CLODSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JqWBswFyht68",
    "outputId": "77349188-126d-4e4d-93fa-929ec33ad573",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from clodsa.augmentors.augmentorFactory import createAugmentor\n",
    "from clodsa.transformers.transformerFactory import transformerGenerator\n",
    "from clodsa.techniques.techniqueFactory import createTechnique\n",
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CBP59dqqht7E"
   },
   "source": [
    "## Creating the augmentor object\n",
    "\n",
    "As explained in the documentation of CLODSA, we need to specify some parameters for the augmentation process, and use them to create an augmentor object.  \n",
    "\n",
    "_The kind of problem_. In this case, we are working in a semantic segmentation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQ5q8WVnht7G"
   },
   "outputs": [],
   "source": [
    "PROBLEM = \"semantic_segmentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D46gdf-4ht7K"
   },
   "source": [
    "_The annotation mode_. The annotation is provided by the name of the folder containing the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrlRg-FVht7M"
   },
   "outputs": [],
   "source": [
    "ANNOTATION_MODE = \"folders\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cn-uF33Oht7S"
   },
   "source": [
    "_The input path_. The input path containing the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_path = '/home/ritesh/Desktop/Codes/ER/datasets/er_unet/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "78jPXCj2ht7U"
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = '/home/ritesh/hdd1/vikram/ER_PR/extracted_patches/train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9kGGhs4ht7a"
   },
   "source": [
    "_The generation mode_. In this case, linear, that is, all the augmentation techniques are applied to all the images of the original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCweCzLeht7c"
   },
   "outputs": [],
   "source": [
    "GENERATION_MODE = \"linear\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6WljljVht7g"
   },
   "source": [
    "_The output mode_. The generated images will be stored in a new folder called augmented_images_nuclei.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4uKKcJUht7i"
   },
   "outputs": [],
   "source": [
    "OUTPUT_MODE = \"folders\"\n",
    "OUTPUT_PATH= '/home/ritesh/hdd1/vikram/ER_PR/ep_aug_all/train/'\n",
    "LABELS_EXTENSION = \".png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9R79LEvVht7o"
   },
   "source": [
    "Using the above information, we can create our augmentor object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQ9wyiQuht7q"
   },
   "outputs": [],
   "source": [
    "augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iXOfuq90ht7w"
   },
   "source": [
    "## Adding the augmentation techniques\n",
    "\n",
    "Now, we define the techniques that will be applied in our augmentation process and add them to our augmentor object. To illustrate the transformations, we will use the following image of the dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "colab_type": "code",
    "id": "1KN354mDht7y",
    "outputId": "b1614308-b428-4d84-b7d2-20c90ad70271"
   },
   "outputs": [],
   "source": [
    "# img = cv2.imread(\"/home/ritesh/Desktop/Codes/ER/datasets/er_aug/test/images/image_3.png\")\n",
    "# label = cv2.imread( \"/home/ritesh/Desktop/Codes/ER/datasets/er_aug/test/labels/image_3.png\")\n",
    "# # changing to the BGR format of OpenCV to RGB format for matplotlib\n",
    "# plt.figure()\n",
    "# plt.imshow(img[:,:,::-1])\n",
    "# plt.title(\"Nuclei\")\n",
    "# plt.figure()\n",
    "# plt.imshow(label[:,:,::-1]*60)\n",
    "# plt.title(\"Label\")\n",
    "# dst = cv2.addWeighted(img,0.7,label,0.3,0)\n",
    "# plt.figure()\n",
    "# plt.imshow(dst[:,:,::-1])\n",
    "# plt.title(\"Blending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vEcmIVFbhX5r"
   },
   "source": [
    "First of all, we must define a transformer generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtFlqLUuhX5s"
   },
   "outputs": [],
   "source": [
    "transformer = transformerGenerator(PROBLEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4PfSKW-ht74"
   },
   "source": [
    "_Rotations:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ajKE-mkDht74"
   },
   "outputs": [],
   "source": [
    "for angle in [90]:\n",
    "    rotate = createTechnique(\"rotate\", {\"angle\" : angle})\n",
    "    augmentor.addTransformer(transformer(rotate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOAc-DfRht7-"
   },
   "source": [
    "Showing the result of applying the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "colab_type": "code",
    "id": "hLbJ2LoMht8A",
    "outputId": "a43875d1-2633-471a-c022-6d871b9e8df3"
   },
   "outputs": [],
   "source": [
    "rotationGenerator = transformer(rotate)\n",
    "# rotateImg,rotateLabel = rotationGenerator.transform(img,label)\n",
    "# plt.figure()\n",
    "# plt.imshow(rotateImg[:,:,::-1])\n",
    "# plt.title(\"Nuclei\")\n",
    "# plt.figure()\n",
    "# plt.imshow(rotateLabel[:,:,::-1]*60)\n",
    "# plt.title(\"Label\")\n",
    "# dst = cv2.addWeighted(rotateImg,0.7,rotateLabel,0.3,0)\n",
    "# plt.figure()\n",
    "# plt.imshow(dst[:,:,::-1])\n",
    "# plt.title(\"Blending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flipping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flip_tp in [1]:\n",
    "    flip = createTechnique(\"flip\", {\"flip\" : flip_tp})\n",
    "    augmentor.addTransformer(transformer(flip))\n",
    "# hflip = createTechnique(\"flip\",{\"flip\":1})\n",
    "# augmentor.addTransformer(transformer(hflip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipGenerator = transformer(flip)\n",
    "# flipImg,flipLabel = flipGenerator.transform(img,label)\n",
    "# plt.figure()\n",
    "# plt.imshow(flipImg[:,:,::-1])\n",
    "# plt.title(\"Nuclei\")\n",
    "# plt.figure()\n",
    "# plt.imshow(flipLabel[:,:,::-1]*60)\n",
    "# plt.title(\"Label\")\n",
    "# dst = cv2.addWeighted(flipImg,0.7,flipLabel,0.3,0)\n",
    "# plt.figure()\n",
    "# plt.imshow(dst[:,:,::-1])\n",
    "# plt.title(\"Blending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PNmIXJv3ht8M"
   },
   "source": [
    "#### Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QnrOFXeoht8O"
   },
   "outputs": [],
   "source": [
    "for translation in [1]:\n",
    "    translation = createTechnique(\"translation\", {\"x\":15,\"y\":-5})\n",
    "    augmentor.addTransformer(transformer(translation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2XXiMPcxht8Y"
   },
   "source": [
    "Showing the result of applying the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "colab_type": "code",
    "id": "dCxUkbllht8Y",
    "outputId": "7113daf5-480c-4712-9f13-119db0096e2a"
   },
   "outputs": [],
   "source": [
    "translationGenerator = transformer(translation)\n",
    "# translationImg,translationLabel = translationGenerator.transform(image,label)\n",
    "# plt.figure()\n",
    "# plt.imshow(translationImg[:,:,::-1])\n",
    "# plt.title(\"Nuclei\")\n",
    "# plt.figure()\n",
    "# plt.imshow(translationLabel[:,:,::-1])\n",
    "# plt.title(\"Label\")\n",
    "# dst = cv2.addWeighted(translationImg,0.7,translationLabel,0.3,0)\n",
    "# plt.figure()\n",
    "# plt.imshow(dst[:,:,::-1])\n",
    "# plt.title(\"Blending\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_YriYliht9E"
   },
   "source": [
    "#### None\n",
    "(to keep also the original image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePk-X8JLht9G"
   },
   "outputs": [],
   "source": [
    "none = createTechnique(\"none\",{})\n",
    "augmentor.addTransformer(transformer(none))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwE-qSYLht9I"
   },
   "source": [
    "## Applying the augmentation process\n",
    "\n",
    "Finally, we apply the augmentation process (this might take some time depending on the number of images of the original dataset and the number of transformations that will be applied). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbW5YVE9ht9I"
   },
   "outputs": [],
   "source": [
    "augmentor.applyAugmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CAnwpjLKht9O"
   },
   "source": [
    "Finally, we can check the amount of images in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiXaXMs6ht9O",
    "outputId": "d052bf2a-dc8c-4efb-fee7-e26b3ace2125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in augmented nuclei folder\n",
      "36368\n",
      "Number of images in augmented nueclei label folder\n",
      "36368\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images in augmented nuclei folder\")\n",
    "!ls /home/ritesh/hdd1/vikram/ER_PR/ep_aug_all/train/images/ | wc -l\n",
    "print(\"Number of images in augmented nueclei label folder\")\n",
    "!ls /home/ritesh/hdd1/vikram/ER_PR/ep_aug_all/train/labels/ | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading npy files and saving them as images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zeJaWGahX6a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "lbl_dir = '/home/arpit/Downloads/8_PR/PR_ER_Data_and_GT/Data_GT_ER_Patches/Smaller_Patches_ER/ER_Weak/256x256_90x90/Train/'\n",
    "for fl in os.listdir(lbl_dir + 'labels_npy/'):\n",
    "     img_npy = np.load(lbl_dir + 'labels_npy/' + fl).astype('uint8')\n",
    "     #save_img(fl, img_npy)\n",
    "     skimage.io.imsave(lbl_dir + 'labels/' + fl.split('.')[0] + '.png', img_npy)\n",
    "     print(fl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbl_dir = '/media/siddarth/119940757D37B1B4/HER2_work/Patches/256x256_160x160/Train/'\n",
    "\n",
    "# img_npy = skimage.io.imread(lbl_dir + 'labels_images/' + 'ROI_17_0_0_0__000.png')\n",
    "\n",
    "# np.unique(img_npy)\n",
    "\n",
    "# img_npy = np.load(lbl_dir + 'Labels/' + 'ROI_3_0_0_0__000.npy')#.astype('uint8')\n",
    "\n",
    "# np.unique(img_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CLODSA_Nuclei.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
